# 網羅的テストケース仕様書

## 1. 目的
本ドキュメントは、リファクタリングの品質と安全性を担保するために作成・実行されるべき網羅的なテストケースの一覧を定義する。これらのテストは、リファクタリングの「あるべき姿」をコードとして表現したものであり、全てが成功（PASS）することがリファクタリング完了の必要条件の一つとなる。

## 2. テストケース一覧

### カテゴリ1: ロジック再現性テスト (iLoRA)
-   **Test 1:** [プロンプト形式] 教師モデルのプロンプトには、`[HistoryEmb]`のようなプレースホルダーだけでなく、実際のアイテム名（映画タイトル）が含まれていること。
-   **Test 2:** [ゲーティング入力] ゲーティングネットワークは、`SASRec`モデルが生成したユーザー/シーケンスの埋め込みを正しく入力として受け取ること。
-   **Test 3:** [ゲーティング出力] ゲーティングネットワークの出力は、LoRAエキスパートの数に応じた次元数を持ち、合計が1となる確率分布（Softmaxの出力）であること。
-   **Test 4:** [重み凍結 - LLM] 教師モデルの学習中、ベースとなっているLLMの重みは凍結されており、勾配が計算されない（`grad`が`None`）こと。
-   **Test 5:** [重み更新 - LoRA] 教師モデルの学習中、LoRA層（`lora_A`, `lora_B`）の重みは学習対象であり、勾配が計算されていること。
-   **Test 6:** [重み更新 - Gating] 教師モデルの学習中、ゲーティングネットワークの重みは学習対象であり、勾配が計算されていること。
-   **Test 7:** [重み凍結 - SASRec] 教師モデルの学習中、ゲーティングの入力として使われる事前学習済み`SASRec`の重みは凍結されていること。
-   **Test 8:** [教師出力 - スコア] `get_teacher_outputs` メソッドが返すランキングスコア（logits）の形状（`batch_size`, `num_items`）とデータ型（`torch.Tensor`）が正しいこと。
-   **Test 9:** [教師出力 - 埋め込み] `get_teacher_outputs` が返す埋め込みの形状（`batch_size`, `hidden_size`）とデータ型が正しいこと。

### カテゴリ2: ロジック再現性テスト (DLLM2Rec)
-   **Test 10:** [損失 - ランキング蒸留] 固定された教師・生徒モデルの出力（logits）に対し、`WeightedBCELoss`が参照実装（`DLLM2Rec/main.py`）に基づいて事前計算した期待値と一致すること。
-   **Test 11:** [損失 - 埋め込み蒸留] 固定された教師・生徒モデルの埋め込みに対し、`EmbeddingDistillationLoss`が事前計算した期待値と一致すること。
-   **Test 12:** [損失 - DRO] 固定された入力と傾向スコア（propensity score）に対し、`DROLoss`が参照実装に基づいて事前計算した期待値と一致すること。
-   **Test 13:** [損失 - 結合] 最終的な蒸留損失が、各損失（CE, Ranking, Embedding, DRO）にそれぞれの重み（`ce_loss_weight`, `ranking_loss_weight`など）を掛けた合計値として正しく計算されていること。
-   **Test 14:** [重み更新 - 生徒] 蒸留の学習中、生徒モデルの重みは学習対象であり、勾配が計算されていること。
-   **Test 15:** [重み凍結 - 教師] 蒸留の学習中、教師モデルは評価モード（`eval()`）であり、その重みは凍結されていること。

### カテゴリ3: データ一貫性・健全性テスト
-   **Test 16:** [データリーク] あるユーザーのインタラクション履歴のうち、検証・テストセットに含まれるアイテムが、学習セットに現れていないことを確認する。
-   **Test 17:** [パディング処理] パディングID（例: 0）が、各モデルの損失計算や評価メトリクスの計算から正しく除外されていること。
-   **Test 18:** [シーケンス生成] `(シーケンス, 次アイテム)` のペアを生成するロジック（例: `[A, B, C] -> ([A], B), ([A, B], C)`）が、仕様通りに正しく動作すること。
-   **Test 19:** [IDマッピング] `movies.dat` や `ratings.dat` の元データのアイテムIDが、モデル内部で使われる埋め込み層のインデックスへ、オフバイワンエラーなく正しくマッピングされていること。
-   **Test 20:** [トークナイザ同期] LLMが使用するトークナイザの語彙と、プロンプト生成時にアイテムIDからアイテム名へ変換する辞書が、正しく対応していること。

### カテゴリ4: モデル挙動・エッジケーステスト
-   **Test 21:** [バッチ独立性] バッチサイズが1の場合とNの場合で、特定のサンプルの出力が変わらないことを確認し、バッチ内の他サンプルの影響を受けないことを保証する。
-   **Test 22:** [推論の決定性] `model.eval()`モード（dropoutなどが無効）では、同じ入力に対して複数回推論を実行しても、常に全く同じ出力が得られること。
-   **Test 23:** [エッジケース - 短いシーケンス] アイテム履歴が1つしかない、あるいは空であるようなユーザーデータを、データローダやモデルがエラーなく適切に処理できること。
-   **Test 24:** [数値安定性] 通常の（極端な値ではない）入力データに対し、モデルの出力や計算される損失が `NaN` や `inf` にならないこと。
-   **Test 25:** [デバイス配置] 学習・推論のフォワードパス中に、モデル内の全てのサブモジュールとテンソルが、意図した単一のデバイス（CPU or CUDA）上に配置されていること。

### カテゴリ5: 設定・パイプラインテスト
-   **Test 26:** [設定上書き] Hydraのコマンドライン引数（例: `train.batch_size=128`）による設定の上書きが、プログラム内で読み込まれる設定オブジェクト（`cfg`）に正しく反映されていること。
-   **Test 27:** [チェックポイント連携1] 保存された生徒モデル (`SASRec`) のチェックポイントが、教師モデル (`iLoRAModel`) の一部として正しく読み込まれ、利用できること。
-   **Test 28:** [チェックポイント連携2] 保存された教師モデル (`iLoRAModel`) のチェックポイントが、蒸留パイプライン (`DistillationTrainer`) に正しく読み込まれ、利用できること。
-   **Test 29:** [スモークテスト] 100件程度の極小データセットを使い、`生徒モデル学習` → `教師モデル学習` → `蒸留` という一連のパイプラインが、エラーを発生させずに最後まで通ること。
-   **Test 30:** [メトリクス計算] 固定されたモデル予測値と正解ラベルのペアに対し、`Recall@K` や `NDCG@K` などの評価メトリクスが、事前計算した期待値と一致すること。

### カテゴリ6: コード品質・静的解析テスト
-   **Test 31:** [Hydra設定検証] `conf/experiment` 内のすべての実験設定ファイルが正常にロードでき、必須キー（`teacher`, `student`, `distill` など）を含んでいること。
-   **Test 32:** [Hydra誤用防止] 実験スクリプト内で `HydraConfig.get()` が直接使用されておらず、ロードされた設定オブジェクト `cfg` が使用されていること（`ValueError: HydraConfig was not set` の防止）。
-   **Test 33:** [未定義名検出] 実験スクリプト内で、未定義の変数やインポート漏れ（`NameError` の原因）が存在しないことを静的解析で確認すること。
-   **Test 34:** [インポートスモークテスト] `src` ディレクトリ内のすべてのPythonモジュールが、`ModuleNotFoundError` や `ImportError` なしに正常にインポートできること。
-   **Test 35:** [引数整合性検証] クラスのインスタンス化や `load_from_checkpoint` の呼び出しにおいて、渡されるキーワード引数が実際のクラス定義（`__init__`）と整合していることを静的解析で確認すること（`TypeError` の防止）。
