# 教師モデル学習時の警告分析 (2025-11-24)

## 概要
教師モデルの学習実行時に発生した警告について調査し、その内容と潜在的な影響を分析した。
対象ログファイル: `result/teacher_20251124_021720/logs/experiment.log`

## 警告内容

### 1. データセットサイズと `limit_data_rows` の不一致
- **ログメッセージ**:
  `src.student.datamodule - WARNING - val_df size (6040) is less than limit_data_rows (150000). Using full validation data.`
  （`test_df`についても同様のメッセージ）
- **説明**:
  この警告は、データローダーが検証用（およびテスト用）データセットのサイズ（6040行）が、設定ファイルで指定されている `limit_data_rows` パラメータ（150,000行）よりも小さいことを示している。
- **潜在的な影響**:
  `limit_data_rows` の値が実際のデータサイズよりも大きいため、データセットが積極的に切り捨てられることなく、利用可能なすべての検証/テストデータが使用されている。これは、特定のデータ量で実験を制限しようとしていない限り、通常は無害であり、無視できる。

### 2. `iLoRAModel` における埋め込み置換の不一致
- **ログメッセージ**:
  `src.teacher.ilora_model - WARNING - Mismatch between number of [HistoryEmb] placeholders (...) and number of valid items (...). Skipping embedding replacement.`
  （多数発生）
- **説明**:
  これはより重要な警告であり、`iLoRAModel` が入力シーケンス内の `[HistoryEmb]` プレースホルダーを実際のアイテム埋め込みに置き換えようとするときに問題が発生していることを示している。具体的には、期待されるプレースホルダーの数（例: 168）と、特定のシーケンスで見つかった有効なアイテムの数（例: 147）が一致していない。この不一致が発生した場合、モデルはその特定の入力に対する埋め込み置換をスキップしている。
- **潜在的な影響**:
  この警告は、LLMが一部のシーケンスで正しいアイテム埋め込みを受け取っていない可能性を示唆しており、教師モデルが正確な推薦を学習し、行う能力に深刻な影響を与える可能性がある。埋め込みがスキップされると、モデルは情報のない、または誤った形式の入力を処理することになり、結果として教師モデルのパフォーマンスが低下する原因となりうる。これは、`docs/implement.md` で報告されている蒸留済み生徒モデルのパフォーマンスが低い問題の間接的な原因である可能性もある。
- **考えられる原因**:
    - **トークン化/パディングの問題**: 入力シーケンスのトークン化、パディング、または切り捨ての方法が、`[HistoryEmb]` トークンの予期される数とシーケンス内の有効なアイテムの実際の数との間に不一致を生じさせている可能性がある。
    - **データ準備ロジック**: LLM入力のために履歴アイテムシーケンスが準備または抽出される方法にバグがある可能性がある。
    - **プロンプト設計**: プロンプトの構造自体、または有効なアイテムをカウントするロジックに問題がある可能性がある。

## 結論と次のステップ
`iLoRAModel` における埋め込み置換の不一致に関する警告は、教師モデルの学習に直接影響を与える深刻な問題である。この問題は、教師モデルの出力品質を低下させ、ひいては知識蒸留の効果を損なう可能性がある。

次のステップとして、この「`[HistoryEmb]` プレースホルダーと有効なアイテム数のミスマッチ」の原因を特定し、修正することに焦点を当てる必要がある。具体的には、`src/teacher/ilora_model.py` および関連するデータ前処理・プロンプト生成ロジックの調査が必要である。
