# LLMベースの推薦検索アプローチ

本書では、推薦システムにおける検索（Retrieval）フェーズでの大規模言語モデル（LLM）の活用アプローチについて、生成型（Generative）から密ベクトル検索（Dense Retrieval）への移行に焦点を当ててまとめます。

## 1. 生成型検索（Generative Retrieval / Text-based）

LLMが本来持つ「テキスト生成能力」をそのまま活用する手法です。推薦タスクを「言語生成タスク」として扱います。

### BIGRec (Bi-step Grounding Paradigm)
- **概念:** 以下の2ステップで構成されます。
    1.  **生成 (Generation):** LLMが推薦アイテムを表す「意味のあるトークン」（例：映画のタイトル）を生成します。
    2.  **接地 (Grounding):** 生成されたテキストをEmbedding化し、類似度検索によって実在するアイテムIDにマッピングします。
- **メリット:** 事前学習された知識を活用できる。未知のアイテム（Zero-shot）でも名前さえ知っていれば推薦候補にできる。
- **デメリット:** 非効率（テキスト生成が遅い）。ハルシネーション（実在しないアイテムの生成）や接地エラー（タイトルの表記ゆれによるミス）が発生しやすい。
- **関連性:** `anyo` プロジェクトが脱却しようとしているベースライン手法です。

### TALLRec (Tuning Framework for Aligning LLMs)
- **概念:** 推薦タスク向けに特化したインストラクションチューニング（Alpacaスタイル）を用いてLLMを微調整します。
- **仕組み:** ユーザー履歴や候補アイテムを自然言語の指示（例：「ユーザーはAとBが好きです。Cを好むでしょうか？」）に変換して入力します。
- **メリット:** Few-shot性能が高い。ドメイン間の汎化性能に優れる。
- **デメリット:** 全候補アイテムに対して長いコンテキストを処理する必要があるため、全件検索（Retrieval）モデルというよりは、少数の候補を順位付けするランキング（Scoring）モデルとしての利用が主となる。

### P5 (Pretrain, Personalized Prompt, and Predict Paradigm)
- **概念:** 様々な推薦タスク（シーケンシャル推薦、評価予測、レビュー生成）を単一のText-to-Textフレームワークに統合します。
- **仕組み:** パーソナライズされたプロンプトを使用し、アイテムIDをテキストトークン（例："item_1234"）またはセマンティックIDとして扱います。
- **メリット:** 複数のタスクを単一のモデルで扱える。
- **デメリット:** IDトークンを使用する場合、新しい語彙の学習が必要。セマンティックIDの構築が複雑になる場合がある。

## 2. 密ベクトル検索（Dense Retrieval / Embedding-based）

LLMをテキスト生成器としてではなく、強力な「エンコーダー」として使用し、検索用の密ベクトル（Embedding）を生成する手法です。

### iLoRA / anyo (現在のアプローチ)
- **概念:** LLMの隠れ状態（Hidden State）を直接利用した検索。
- **仕組み:**
    1.  **エンコード:** LLMがユーザー履歴を処理し、最後の隠れ状態を出力します。
    2.  **射影 (Projection):** この状態をアイテムEmbedding空間に射影します。
    3.  **検索:** 事前に計算されたアイテムEmbeddingに対して近傍探索を行います。
- **メリット:**
    -   **効率性:** 自己回帰的なテキスト生成（トークンごとの生成）が不要で、1回のフォワードパスで済むため高速。
    -   **正確性:** ハルシネーションが発生しない（実在するアイテムベクトルとの類似度で決まるため）。
    -   **メモリ:** `lm_head`（語彙数分の出力層）を削除可能（`anyo`での実装済み）。
- **デメリット:** LLMの出力空間とアイテム空間を一致させるためのアライメント学習が必要。

### LLaRA (LLM adapted for Dense Retrieval)
- **概念:** LLMを密ベクトル検索器（Dense Retriever）として機能させるための事後適応（Post-hoc adaptation）。
- **仕組み:** クエリ（ユーザープロファイル）とドキュメント（アイテム）の両方をLLMでエンコードし、Embeddingとして扱います。
- **関連性:** LLMを単なる生成器ではなく「バックボーンエンコーダー」として利用するトレンドを裏付けるものです。

## 比較まとめ

| 特徴 | 生成型 (BIGRec) | 密ベクトル検索 (anyo) |
| :--- | :--- | :--- |
| **出力** | テキスト (アイテム名) | ベクトル (アイテムEmbedding) |
| **推論ステップ** | マルチステップ (トークン数分) | シングルステップ (1回) |
| **接地 (Grounding)** | 必要 (テキスト -> ID) | 暗黙的 (ベクトル -> ID) |
| **ハルシネーション** | あり得る | あり得ない (コーパス内に限定) |
| **速度** | 遅い | 速い |

## 結論
推薦システムの候補生成（Retrieval）フェーズにおいては、効率性と堅牢性の観点から、`anyo` のような **密ベクトル検索（Dense Retrieval）** への移行が進んでいます。生成型アプローチは強力ですが、最終的なリランキングや、理由説明（Explanation）の生成など、高度な推論が必要なフェーズにより適しています。
