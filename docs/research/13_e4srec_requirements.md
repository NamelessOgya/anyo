# E4SRec: Infrastructure Requirements & Training Details

ユーザー様のリクエストに基づき、E4SRecの学習に必要なインフラと時間について調査しました。

## 1. 推奨インフラ (Official READMEより)

公式リポジトリのデフォルト設定は、非常に大規模なモデル (**70B**) を前提としています。

*   **Base Model:** `garage-bAInd/Platypus2-70B-instruct` (700億パラメータ)
*   **GPU要件:**
    *   **必須:** NVIDIA A800 (80GB) x 2枚以上
    *   **推奨:** NVIDIA A800 (80GB) x 8枚
*   **メモリ:** 70Bモデルをロードするだけで、量子化(8bit)しても約70GB〜80GBのVRAMが必要です。学習にはさらに勾配やOptimizerの状態保存が必要なため、マルチGPUが必須となります。

## 2. 現実的な運用 (7Bモデルの場合)

コード (`finetune.py`) を確認したところ、`huggyllama/llama-7b` などの小型モデルもサポートされています。
7Bモデルを使用する場合、要件は劇的に下がります。

*   **Base Model:** `Llama-2-7b` / `Llama-3-8b` 等
*   **GPU要件:**
    *   **学習 (LoRA):** NVIDIA A100 (40GB/80GB) x 1枚、または RTX 3090/4090 (24GB) x 1枚 (8bit/4bit量子化必須)
    *   **推論:** RTX 3090 (24GB) x 1枚で十分動作可能
*   **メリット:** `anyo` の開発環境でも十分に動作可能なレベルです。

## 3. 学習時間 (見積もり)

`finetune.py` のデフォルト設定 (`num_epochs: 3`, `batch_size: 128`) に基づく概算です。

| モデルサイズ | GPU構成 | データセット規模 | 学習時間 (目安) |
| :--- | :--- | :--- | :--- |
| **70B** | A800 x 8 | Beauty (小規模) | 数時間 〜 半日 |
| **7B** | A100 x 1 | Beauty (小規模) | 1時間以内 |
| **7B** | A100 x 1 | MovieLens-1M (中規模) | 数時間 |

## 4. 結論
*   公式推奨の **70Bモデルは、大学や企業の研究所レベルの計算資源 (A800 x 8) が必要** であり、個人の開発環境では再現困難です。
*   ただし、**7Bモデルに変更すれば、一般的なGPUサーバー (A100 x 1) やハイエンドPCで十分に学習・運用可能** です。
*   `anyo` と比較する場合、まずは **7Bモデルでの再現** を目指すのが現実的です。
