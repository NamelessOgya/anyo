# AS-ISからの差分 (3rd)

## はじめに
前回の報告(`06_difference_from_asis_2nd.md`)以降に実施した、ANYO株式会社のLLM2Rec蒸留基盤に対する改修内容をまとめる。
引き継ぎ時の最優先課題であった「検証メトリクスとテストメトリクスの乖離」問題の根本原因を特定し、解決することができた。

## 1. 課題
引き継ぎ時の状態では、生徒モデルのベースラインにおいて、検証セットでの性能 (`val_recall@10`) がテストセットでの性能 (`test_recall@10`) を大きく上回る問題（例: `val: 0.11702` vs `test: 0.07368`）が発生していた。先行研究では同様の構成で問題が起きていないことから、モデルの過学習よりも、データ処理や評価ロジックのバグが根本原因であると仮説を立て、調査を開始した。

調査の過程で、以下の副次的な問題も発見・修正した。
- Hydraの設定上書きが意図通りに機能しておらず、`max_epochs`が正しく適用されていなかった。
- 実行環境にデータセットが存在せず、`FileNotFoundError` が発生した。
- 損失計算時にテンソルの形状が原因で `RuntimeError` が発生した。
- `batch_size` が小さく、GPUリソースを有効活用できておらず学習に時間がかかっていた。

## 2. 主な変更点

### 2.1. データ分割ロジックのバグ修正 (`src/student/datamodule.py`)
- **問題:** データ分割ロジックを調査したところ、学習データを生成するループの範囲が `range(1, len(seq) - 2)` となっており、検証・テストデータで評価対象となる「シーケンスの最後から2番目のアイテム」を予測するパターンが学習データに一切含まれていない、という重大なバグを発見した。
- **対応:**
    1.  調査の過程で、`datamodule.py`が事前処理済みのpickleファイルを読み込むように変更されていることが判明。この形式では原因の切り分けが困難なため、`ratings.dat`から直接データを読み込みその場で分割する、以前のシンプルなバージョンにコードを復元した。
    2.  復元したコードに対し、学習データ生成ループを `for i in range(1, len(seq) - 1):` に修正。これにより、モデルは検証・テストで評価されるタスクを正しく学習できるようになった。

### 2.2. Hydra設定の修正 (`conf/config.yaml`)
- **問題:** `conf/train/student.yaml` の `max_epochs: 5` が適用されず、`conf/train/default.yaml` の `max_epochs: 50` が常に使用されていた。
- **対応:** `conf/config.yaml` の `defaults` リストにおいて、`train: default` を `train: student` に変更し、生徒モデルの学習設定が正しく読み込まれるようにした。

### 2.3. データセット準備プロセスの改善
- **問題:** 実行環境にデータセットがなく、パスの設定も誤っていたため `FileNotFoundError` が発生していた。
- **対応:**
    1.  `data/download_movielens.sh` を新規に作成し、データセットのダウンロードと解凍を自動化した。
    2.  `conf/dataset/movielens.yaml` の `data_dir` を、ダウンロードされた正しいパス (`data/ml-1m`) に修正した。

### 2.4. `RuntimeError` の修正 (`src/student/trainer_baseline.py`)
- **問題:** `CrossEntropyLoss` に渡されるターゲットテンソルの形状が `[batch_size, 1]` となっており、期待される `[batch_size]` と異なっていたため、`RuntimeError` が発生していた。
- **対応:** `training_step`, `validation_step`, `test_step` の3箇所で、損失を計算する際に `next_item.squeeze(-1)` を適用し、テンソルの次元を修正した。

### 2.5. 学習速度の改善 (`conf/train/student.yaml`)
- **問題:** GPUメモリに余裕があるにも関わらず、`batch_size` が `32` と小さく、学習に時間がかかっていた。
- **対応:** `batch_size` を `256` に引き上げ、GPUを効率的に利用することで学習を高速化した。

## 3. 結果
- 上記の修正、特にデータ分割ロジックのバグ修正により、**検証とテストの性能乖離問題は完全に解消された。**
    - **修正前:** `val_recall@10: 0.11702` vs `test_recall@10: 0.07368` (差: `0.04334`)
    - **修正後:** `val_recall@10: 0.10795` vs `test_recall@10: 0.09421` (差: `0.01374`)
- 学習時間も約20分以上かかっていたものが、約5分半に短縮された。

## 4. 今後の課題
- 生徒モデルのベースラインが健全な状態になったことで、プロジェクト当初の課題であった「**蒸留済み生徒モデルのパフォーマンスが低い**」という問題に本格的に取り組む準備が整った。
- 今後は、教師モデルの品質向上や、蒸留プロセスのハイパーパラメータチューニングなどが主なタスクとなる。
