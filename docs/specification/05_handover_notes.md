# 引き継ぎノート (Handover Notes)

このドキュメントは、後任のエージェントが本プロジェクトの開発をスムーズに引き継ぐためのものです。

---

## 1. 現状のサマリー

### 1.1. プロジェクト目標

本プロジェクトの最終目標は、**LLM (大規模言語モデル) を教師モデルとして活用し、シーケンシャル推薦モデル (生徒モデル) へ知識蒸留を行うための研究開発基盤を構築すること**です。
`iLoRA` と `DLLM2Rec` の論文で提案されているアーキテクチャを参考に、独自の解釈で実装を進めています。

### 1.2. 実装状況

現在、プロジェクトの基本的な骨格が完成し、各コンポーネントが連携して動作するためのスケルトン実装と、それらを検証する単体テストが完了しています。

- **全体構成**: Hydraによる設定管理、Poetryによる依存関係管理、Dockerによる実行環境が整備されています。
- **ソースコード**: `src/` 配下に、`core`, `student`, `teacher`, `distill`, `exp` の各モジュールがスケルトンとして実装済みです。
- **テスト**: `tests/` 配下に各モジュールの単体テストが実装されており、**すべてのテストが成功 (passed) する状態**です。
- **ドキュメント**: `docs/specification` 配下に、概要、開発ノート、テストケース、実行ガイドが整備されています。

**注意**: 教師モデルである `iLoRAModel` は、まだ多くの部分が概念実証のためのダミー実装（ランダムな値を返すなど）となっています。

---

## 2. プロジェクト構造と規約

### 2.1. 主要ディレクトリ

- `conf/`: Hydraの設定ファイル群。
- `src/`: Pythonのソースコード。
  - `core/`: プロジェクト共通のユーティリティ。
  - `student/`: 生徒モデル (`SASRec`) 関連。
  - `teacher/`: 教師モデル (`iLoRAModel`) 関連。
  - `distill/`: 知識蒸留のロジック関連。
  - `exp/`: 実験実行のエントリポイント。
- `tests/`: `pytest`によるテストコード。
- `docs/`: 設計書や仕様書。
- `cmd/`: 各種実行スクリプト。
- `ref_repositories/`: 参考にした論文のコードリポジトリ（直接のインポートは禁止）。

### 2.2. 重要な規約

- **設計書の遵守**: `docs/implement.md` は本プロジェクトの唯一の設計書です。**このファイルの編集は禁止**されています。
- **開発記録**: 機能追加や大きな変更を行った際は、`docs/specification/02_development_notes_ja.md` に思考プロセスや実装内容を記録してください。
- **参考コードの扱い**: `ref_repositories/` 内のコードはあくまで参考資料です。ロジックを理解した上で、本プロジェクトの設計に合わせて再実装してください。直接のコピー＆ペーストやインポートは禁止です。

---

## 3. 開発・実行環境

### 3.1. Dockerコンテナ

開発は `ilora-dev-container` という名前のDockerコンテナ内で完結します。

- **コンテナの起動**:
  ```bash
  docker run -d --name ilora-dev-container -v "$(pwd)":/workspace -w /workspace --gpus all -it ilora-dllm2rec:latest
  ```
- **コンテナ内でのコマンド実行**:
  ```bash
  docker exec -it ilora-dev-container bash
  ```

### 3.2. テストの実行

テストは `pytest` を使用します。コンテナ内で以下のコマンドを実行してください。

```bash
# 個別テストの実行
poetry run pytest tests/teacher/test_ilora_model.py

# 全テストの実行
poetry run pytest
```
**重要**: `PYTHONPATH` はコンテナ環境で設定済みです。すべてのテストがパスすることを確認しながら開発を進めてください。

---

## 4. 残されたタスクと次のステップ

### 4.1. 今後のタスクリスト

1.  **教師モデル (`iLoRAModel`) の詳細実装**:
    -   [ ] **プロンプトエンジニアリング**: アイテム履歴を自然言語プロンプトに変換するロジックの実装。
    -   [ ] **動的なLoRAアダプターの結合**: `peft`ライブラリを活用した、より効率的なフォワードパスの実装。
    -   [ ] **出力のマッピング**: LLMの出力ロジットから推薦アイテムのスコアを計算するロジックの洗練。

2.  **データ関連処理の強化**:
    -   [ ] **データブリッジ (`src/distill/data_bridge.py`) の実装**: 教師モデルと生徒モデル間のデータ形式の違いを吸収する層の実装。
    -   [ ] **選択的蒸留 (`src/distill/selection_policy.py`) の高度化**: より効果的な蒸留サンプルを選択する高度なポリシーの実装。

3.  **実験と評価**:
    -   [ ] **チェックポイント管理**: 学習済みモデルの保存・ロード機能の具体化。
    -   [ ] **実験の実行と分析**: `cmd/` スクリプトを用いた本格的な実験の実施。

### 4.2. 次にすべきこと

上記のタスクリストに基づき、**次に着手すべき最優先タスクは「1. 教師モデル (`iLoRAModel`) の詳細実装」**です。

具体的には、`src/teacher/ilora_model.py` の `forward` メソッド内にある以下のダミー実装を、実際のロジックに置き換えることから始めてください。

-   **プロンプト変換**: `dummy_llm_input_ids` を、`item_seq` から生成した実際のプロンプトトークンに置き換える。
-   **LoRAエキスパートの推論**: `expert_output_logits` を、`torch.randn` ではなく、`peft` を使って各LoRAエキスパートを適用したLLMの推論結果に置き換える。

この実装を進めることで、教師モデルが意味のある推薦スコアを生成できるようになり、知識蒸留の基盤が完成に近づきます。
